{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df8d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from latentmi import lmi, ksg\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23773f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellCycleDataset(Dataset):\n",
    "    \"\"\"Dataset for cell cycle phase classification from multi-channel images.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, transform: Optional[Callable] = None, \n",
    "                 max_samples: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to CellCycle directory containing phase subdirectories\n",
    "            transform: Optional transform to apply to images\n",
    "            max_samples: Maximum number of samples to load (None = all)\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Define cell cycle phases\n",
    "        self.phases = ['Anaphase', 'G1', 'G2', 'Metaphase', 'Prophase', 'S', 'Telophase']\n",
    "        self.phase_to_idx = {phase: idx for idx, phase in enumerate(self.phases)}\n",
    "        \n",
    "        # Collect all samples\n",
    "        print('Indexing dataset...')\n",
    "        self.samples = []\n",
    "        \n",
    "        for phase in self.phases:\n",
    "            phase_dir = self.data_dir / phase\n",
    "            if not phase_dir.exists():\n",
    "                continue\n",
    "                \n",
    "            # Find all unique cell IDs (by looking at Ch3 files)\n",
    "            ch3_files = sorted(phase_dir.glob('*_Ch3.ome.jpg'))\n",
    "            \n",
    "            for ch3_file in ch3_files:\n",
    "                # Extract base name (e.g., \"49033\" from \"49033_Ch3.ome.jpg\")\n",
    "                base_name = ch3_file.stem.replace('_Ch3.ome', '')\n",
    "                \n",
    "                # Check if all 3 channels exist\n",
    "                ch4_file = phase_dir / f\"{base_name}_Ch4.ome.jpg\"\n",
    "                ch6_file = phase_dir / f\"{base_name}_Ch6.ome.jpg\"\n",
    "                \n",
    "                if ch4_file.exists() and ch6_file.exists():\n",
    "                    self.samples.append({\n",
    "                        'ch3': ch3_file,\n",
    "                        'ch4': ch4_file,\n",
    "                        'ch6': ch6_file,\n",
    "                        'phase': phase,\n",
    "                        'label': self.phase_to_idx[phase]\n",
    "                    })\n",
    "                    \n",
    "                    if max_samples and len(self.samples) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if max_samples and len(self.samples) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f'Found {len(self.samples)} valid cells')\n",
    "        for phase in self.phases:\n",
    "            count = sum(1 for s in self.samples if s['phase'] == phase)\n",
    "            print(f'  {phase}: {count}')\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load all 3 channels\n",
    "        ch3 = Image.open(sample['ch3']).convert('L')\n",
    "        ch4 = Image.open(sample['ch4']).convert('L')\n",
    "        ch6 = Image.open(sample['ch6']).convert('L')\n",
    "        \n",
    "        # Convert to tensors and stack\n",
    "        ch3_t = transforms.ToTensor()(ch3)\n",
    "        ch4_t = transforms.ToTensor()(ch4)\n",
    "        ch6_t = transforms.ToTensor()(ch6)\n",
    "        \n",
    "        img = torch.cat([ch3_t, ch4_t, ch6_t], dim=0)  # Shape: [3, H, W]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, sample['label']\n",
    "\n",
    "\n",
    "def add_gauss(x: torch.Tensor, sigma: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"Add Gaussian noise to image.\"\"\"\n",
    "    return x + torch.randn_like(x) * sigma\n",
    "\n",
    "\n",
    "def pixelate(x: torch.Tensor, scale: int = 4) -> torch.Tensor:\n",
    "    \"\"\"Pixelate image by downsampling and upsampling.\"\"\"\n",
    "    h, w = x.shape[-2:]\n",
    "    small = F.avg_pool2d(x, kernel_size=scale, stride=scale)\n",
    "    return F.interpolate(small, size=(h, w), mode='nearest')\n",
    "\n",
    "\n",
    "def create_model(num_classes: int, device: torch.device) -> nn.Module:\n",
    "    \"\"\"Create MobileNetV3-small model adapted for 3-channel input.\"\"\"\n",
    "    model = models.mobilenet_v3_small(weights='DEFAULT')\n",
    "    \n",
    "    # Modify first conv layer to accept 3 channels (already 3, but re-init for clarity)\n",
    "    model.features[0][0] = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "    \n",
    "    # Modify classifier for num_classes\n",
    "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, noise_fn: Optional[Callable],\n",
    "                device: torch.device, n_epochs: int = 50, lr: float = 1e-3) -> None:\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in tqdm(range(n_epochs), leave=True):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Apply noise if specified\n",
    "            if noise_fn:\n",
    "                x = noise_fn(x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "def compute_mi(model: nn.Module, data_loader: DataLoader, noise_fn: Optional[Callable],\n",
    "               device: torch.device, num_classes: int = 7) -> Tuple[float, float, dict]:\n",
    "    \"\"\"Compute mutual information between representations and labels.\n",
    "    \n",
    "    Returns:\n",
    "        mi_score: Continuous MI from representations\n",
    "        discrete_mi: Overall discrete MI\n",
    "        ova_mis: Dictionary mapping class names to one-vs-all MIs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    representations = []\n",
    "    targets = []\n",
    "    y_hats = []\n",
    "    \n",
    "    # Create hook to extract features\n",
    "    features = {}\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hook on last layer before classifier\n",
    "    model.classifier[0].register_forward_hook(get_features('last_layer'))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Apply noise if specified\n",
    "            if noise_fn:\n",
    "                x = noise_fn(x)\n",
    "            \n",
    "            y_hat = model(x)\n",
    "            representations.append(features['last_layer'].cpu())\n",
    "            targets.append(y)\n",
    "            y_hats.append(y_hat.cpu())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = torch.cat(representations).numpy()\n",
    "    Y = torch.cat(targets).numpy()\n",
    "    # convert Y to one-hot encoding\n",
    "    Y_onehot = np.eye(num_classes)[Y]\n",
    "    print(f\"Labels one-hot shape: {Y_onehot.shape}\")\n",
    "    Y_hats_onehot = torch.cat(y_hats).numpy()\n",
    "    print(f\"Predictions one-hot shape: {Y_hats_onehot.shape}\")\n",
    "    # convert to non-onehot\n",
    "    Y_hats = np.argmax(Y_hats_onehot, axis=1)\n",
    "    print(f\"Predictions non one-hot shape: {Y_hats.shape}\")\n",
    "    \n",
    "    print(f\"Representations shape: {X.shape}, Labels shape: {Y.shape}, Predictions shape: {Y_hats.shape}\")\n",
    "    \n",
    "    # Calculate MI using latentmi\n",
    "    pmis, _, _ = lmi.estimate(X, Y_onehot, validation_split=0.3, batch_size=512, \n",
    "                             epochs=50, quiet=False)\n",
    "    mi_score = np.nanmean(pmis)\n",
    "    \n",
    "    print(f\"MI score (representation): {mi_score:.4f}\")\n",
    "\n",
    "    discrete_mi = ksg.midd(Y, Y_hats)\n",
    "    print(f\"MI score (discrete): {discrete_mi:.4f}\")\n",
    "    \n",
    "    # Compute one-vs-all MIs with balanced resampling\n",
    "    print(\"\\nComputing one-vs-all MIs...\")\n",
    "    phase_names = ['Anaphase', 'G1', 'G2', 'Metaphase', 'Prophase', 'S', 'Telophase']\n",
    "    ova_mis = {}\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_name = phase_names[class_idx] if class_idx < len(phase_names) else f\"Class_{class_idx}\"\n",
    "        \n",
    "        # Create binary labels (1 for current class, 0 for all others)\n",
    "        Y_binary = (Y == class_idx).astype(int)\n",
    "        Y_hats_binary = (Y_hats == class_idx).astype(int)\n",
    "        \n",
    "        # Count samples in each binary class\n",
    "        n_positive = np.sum(Y_binary)\n",
    "        n_negative = len(Y_binary) - n_positive\n",
    "        \n",
    "        # Balanced resampling: take min of the two classes and sample equally\n",
    "        n_samples = min(n_positive, n_negative)\n",
    "        \n",
    "        positive_indices = np.where(Y_binary == 1)[0]\n",
    "        negative_indices = np.where(Y_binary == 0)[0]\n",
    "        \n",
    "        # Randomly sample n_samples from each class\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        sampled_positive = np.random.choice(positive_indices, size=n_samples, replace=True)\n",
    "        sampled_negative = np.random.choice(negative_indices, size=n_samples, replace=True)\n",
    "        \n",
    "        # Combine and shuffle\n",
    "        balanced_indices = np.concatenate([sampled_positive, sampled_negative])\n",
    "        np.random.shuffle(balanced_indices)\n",
    "        \n",
    "        # Get balanced labels and predictions\n",
    "        Y_binary_balanced = Y_binary[balanced_indices]\n",
    "        Y_hats_binary_balanced = Y_hats_binary[balanced_indices]\n",
    "        \n",
    "        # Compute MI for this one-vs-all binary classification\n",
    "        ova_mi = ksg.midd(Y_binary_balanced, Y_hats_binary_balanced)\n",
    "        ova_mis[class_name] = ova_mi\n",
    "        \n",
    "        print(f\"  {class_name} (one-vs-all, balanced {n_samples} per class): {ova_mi:.4f} bits\")\n",
    "    \n",
    "    return mi_score, discrete_mi, ova_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df076be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Main Experiment ====================\n",
    "def run_experiment(data_dir: str, output_dir: str, noise_fn: Optional[Callable],\n",
    "                   tag: str, device: torch.device, n_epochs: int = 50,\n",
    "                   max_samples: Optional[int] = None) -> Tuple[float, float, dict]:\n",
    "    \"\"\"Run a single noise experiment.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting experiment: {tag}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "    ])\n",
    "    \n",
    "    dataset = CellCycleDataset(data_dir, transform=tfm, max_samples=max_samples)\n",
    "    \n",
    "    # Split dataset\n",
    "    n_total = len(dataset)\n",
    "    n_train = int(n_total * 0.5)\n",
    "    train_inds = np.random.choice(n_total, size=n_train, replace=False)\n",
    "    test_inds = np.setdiff1d(np.arange(n_total), train_inds)\n",
    "    \n",
    "    train_ds = Subset(dataset, train_inds)\n",
    "    test_ds = Subset(dataset, test_inds)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=1)\n",
    "    test_dl = DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=1)\n",
    "    \n",
    "    print(f'Dataset split: {n_train} train, {len(test_inds)} test')\n",
    "    \n",
    "    # Create and train model\n",
    "    num_classes = len(dataset.phases)\n",
    "    model = create_model(num_classes, device)\n",
    "    \n",
    "    train_model(model, train_dl, noise_fn, device, n_epochs=n_epochs)\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_path = os.path.join(output_dir, f\"model_{tag}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "    \n",
    "    # Compute MI\n",
    "    mi_score, discrete_mi, ova_mis = compute_mi(model, test_dl, noise_fn, device, num_classes)\n",
    "    \n",
    "    return mi_score, discrete_mi, ova_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f691079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "Starting experiment: clean\n",
      "============================================================\n",
      "Indexing dataset...\n",
      "Found 32266 valid cells\n",
      "  Anaphase: 15\n",
      "  G1: 14333\n",
      "  G2: 8601\n",
      "  Metaphase: 68\n",
      "  Prophase: 606\n",
      "  S: 8616\n",
      "  Telophase: 27\n",
      "Dataset split: 16133 train, 16133 test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2396f78bf00248838baec93f31bfa622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29271214a75540e89d7b859899c52f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.6158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095f661ef08d49439bfee881015c6e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Loss: 0.4559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d65ab0b3a443cdb40ab92d6193bb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Loss: 0.4113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432274c72a18491a87f5089991b2df1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Loss: 0.3686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e839450e7744c8ad1fbc5878f88399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Loss: 0.3410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b290ec5a40940138b0a62e24674ee9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Loss: 0.3203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101aa4a8bf7841329de3fea4520854d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Loss: 0.2787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3578b53d6998442fb2b33dc7a9d3d1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Loss: 0.2619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd866532ab843d78de8fa6d966613bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Loss: 0.2546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a47d41c3674a1fb2760a49773dd193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Loss: 0.2146\n",
      "Saved model to cellcycle_models/model_clean.pt\n",
      "Labels one-hot shape: (16133, 7)\n",
      "Predictions one-hot shape: (16133, 7)\n",
      "Predictions non one-hot shape: (16133,)\n",
      "Representations shape: (16133, 1024), Labels shape: (16133,), Predictions shape: (16133,)\n",
      "epoch 49 (of max 50) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»MI score (representation): 1.0562\n",
      "MI score (discrete): 0.7814\n",
      "\n",
      "Computing one-vs-all MIs...\n",
      "  Anaphase (one-vs-all, balanced 8 per class): 0.2190 bits\n",
      "  G1 (one-vs-all, balanced 7065 per class): 0.5258 bits\n",
      "  G2 (one-vs-all, balanced 4355 per class): 0.2733 bits\n",
      "  Metaphase (one-vs-all, balanced 34 per class): 0.0456 bits\n",
      "  Prophase (one-vs-all, balanced 327 per class): 0.4420 bits\n",
      "  S (one-vs-all, balanced 4332 per class): 0.1270 bits\n",
      "  Telophase (one-vs-all, balanced 12 per class): 1.0000 bits\n",
      "\n",
      "============================================================\n",
      "Starting experiment: gauss_0.001000\n",
      "============================================================\n",
      "Indexing dataset...\n",
      "Found 32266 valid cells\n",
      "  Anaphase: 15\n",
      "  G1: 14333\n",
      "  G2: 8601\n",
      "  Metaphase: 68\n",
      "  Prophase: 606\n",
      "  S: 8616\n",
      "  Telophase: 27\n",
      "Dataset split: 16133 train, 16133 test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625266c41e494d078d88c22c6c333f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39791e7dbfc74b3eae5c55cf300f7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.6160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f699c77373d42c3b7166c773232481f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Loss: 0.4355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ea34b24042422b949f78bec50e8ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Loss: 0.3880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d829eade1b944438af0625e3de98b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Loss: 0.3437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b509de6148642b6952f9b2038b0ea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Loss: 0.3339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ecd6cf07584af8b112754a9493485d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Loss: 0.3272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6106d0d9474dbc9b4cf8dd395c1e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m noise_fn, tag \u001b[38;5;129;01min\u001b[39;00m experiments:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         mi_score, discrete_mi, ova_mis = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnoise_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_samples\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m         results[tag] = {\n\u001b[32m     32\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mmi_score\u001b[39m\u001b[33m'\u001b[39m: mi_score,\n\u001b[32m     33\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mdiscrete_mi\u001b[39m\u001b[33m'\u001b[39m: discrete_mi,\n\u001b[32m     34\u001b[39m             **{\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mova_mi_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ova_mis.items()}\n\u001b[32m     35\u001b[39m         }\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(data_dir, output_dir, noise_fn, tag, device, n_epochs, max_samples)\u001b[39m\n\u001b[32m     32\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(dataset.phases)\n\u001b[32m     33\u001b[39m model = create_model(num_classes, device)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[32m     38\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, noise_fn, device, n_epochs, lr)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs), leave=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    117\u001b[39m     epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Apply noise if specified\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1441\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1278\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1279\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1280\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/multiprocessing/connection.py:948\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    945\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/gokulg/miniforge3/envs/scaling/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data_dir = 'data/cellcycle/CellCycle'\n",
    "output_dir = 'cellcycle_models'\n",
    "epochs = 10\n",
    "max_samples = 1000000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "experiments = [\n",
    "    (None, \"clean\"),\n",
    "] + [\n",
    "    (lambda x, s=s: add_gauss(x, s), f\"gauss_{s:.6f}\")\n",
    "    for s in np.logspace(-3, 1, 10)\n",
    "] + [\n",
    "    (lambda x, sc=sc: pixelate(x, sc), f\"pix_{sc}x\")\n",
    "    for sc in [2,4,7,8,14,16,28,32,56,112,224]\n",
    "]\n",
    "\n",
    "# Run all experiments\n",
    "results = {}\n",
    "for noise_fn, tag in experiments:\n",
    "    try:\n",
    "        mi_score, discrete_mi, ova_mis = run_experiment(\n",
    "            data_dir, \n",
    "            output_dir, \n",
    "            noise_fn, \n",
    "            tag, \n",
    "            device,\n",
    "            n_epochs=epochs,\n",
    "            max_samples=max_samples\n",
    "        )\n",
    "        results[tag] = {\n",
    "            'mi_score': mi_score,\n",
    "            'discrete_mi': discrete_mi,\n",
    "            **{f'ova_mi_{k}': v for k, v in ova_mis.items()}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in experiment {tag}: {e}\")\n",
    "        results[tag] = {'mi_score': np.nan, 'discrete_mi': np.nan}\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame([\n",
    "    {'experiment': tag, **scores}\n",
    "    for tag, scores in results.items()\n",
    "])\n",
    "results_path = os.path.join(output_dir, 'results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"\\nResults saved to {results_path}\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd89ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb4079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
