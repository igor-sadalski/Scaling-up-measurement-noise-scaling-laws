{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ce33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\n",
    "    \"/home/jupyter/igor_repos/exploration/noise_scaling_laws/Scaling-up-measurement-noise-scaling-laws/collect_mi_results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc63243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "df = df.rename(columns={\"algorithm\": \"method\", \"signal\": \"metric\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751f177",
   "metadata": {},
   "source": [
    "### fitting noise scaling laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the plot for cell scaling laws\n",
    "if 'final_results' in locals() and len(final_results) > 0:\n",
    "    # Get unique combinations of metric and method\n",
    "    metrics = final_results[\"metric\"].unique()\n",
    "    methods = final_results[\"method\"].unique()\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(len(metrics), len(methods), figsize=(4 * len(methods), 4 * len(metrics)))\n",
    "\n",
    "    # Handle case where there's only one metric or method\n",
    "    if len(metrics) == 1 and len(methods) == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif len(metrics) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif len(methods) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Color scheme for different quality levels (UMI counts)\n",
    "    qualities = sorted(final_results[\"quality\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(qualities)))\n",
    "    quality_color_map = dict(zip(qualities, colors))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, method in enumerate(methods):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Filter data for this metric and method combination\n",
    "            subset = final_results[(final_results[\"metric\"] == metric) & (final_results[\"method\"] == method)]\n",
    "\n",
    "            if len(subset) > 0:\n",
    "                # Plot points for each quality level\n",
    "                for quality in qualities:\n",
    "                    quality_data = subset[subset[\"quality\"] == quality]\n",
    "                    if len(quality_data) > 0:\n",
    "                        # Group by size to handle multiple seeds\n",
    "                        grouped = quality_data.groupby(\"size\")\n",
    "\n",
    "                        x_vals = []\n",
    "                        y_means = []\n",
    "                        y_stds = []\n",
    "\n",
    "                        for size, group in grouped:\n",
    "                            x_vals.append(size)\n",
    "                            mi_values = group[\"mi_value\"]\n",
    "                            y_means.append(mi_values.mean())\n",
    "                            y_stds.append(mi_values.std() if len(mi_values) > 1 else 0)\n",
    "\n",
    "                        x_vals = np.array(x_vals)\n",
    "                        y_means = np.array(y_means)\n",
    "                        y_stds = np.array(y_stds)\n",
    "\n",
    "                        # Sort by x_vals for proper line connection\n",
    "                        sort_idx = np.argsort(x_vals)\n",
    "                        x_vals = x_vals[sort_idx]\n",
    "                        y_means = y_means[sort_idx]\n",
    "                        y_stds = y_stds[sort_idx]\n",
    "\n",
    "                        # Plot error bars if there are multiple seeds, otherwise scatter points\n",
    "                        if np.any(y_stds > 0):\n",
    "                            ax.errorbar(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                yerr=y_stds,\n",
    "                                color=quality_color_map[quality],\n",
    "                                fmt=\"o\",\n",
    "                                capsize=5,\n",
    "                                capthick=2,\n",
    "                                alpha=0.7,\n",
    "                                markersize=6,\n",
    "                                label=f\"Quality {quality:.3f}\",\n",
    "                            )\n",
    "                        else:\n",
    "                            ax.scatter(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                color=quality_color_map[quality],\n",
    "                                alpha=0.7,\n",
    "                                s=50,\n",
    "                                label=f\"Quality {quality:.3f}\",\n",
    "                            )\n",
    "\n",
    "                        # Connect points with lines for each quality level\n",
    "                        ax.plot(x_vals, y_means, color=quality_color_map[quality], linestyle=\"-\", linewidth=1.5, alpha=0.8)\n",
    "\n",
    "                        # Plot fitted curve for this quality with uncertainty bands (if available)\n",
    "                        if 'A_cell' in quality_data.columns and not quality_data['A_cell'].isna().all():\n",
    "                            size_range = np.linspace(quality_data[\"size\"].min(), quality_data[\"size\"].max(), 100)\n",
    "                            # Use the fitted parameters (they should be the same for all points with same quality/metric/method)\n",
    "                            A_cell = quality_data[\"A_cell\"].iloc[0]\n",
    "                            A_cell_err = quality_data[\"A_cell_err\"].iloc[0]\n",
    "                            B_cell = quality_data[\"B_cell\"].iloc[0]\n",
    "                            B_cell_err = quality_data[\"B_cell_err\"].iloc[0]\n",
    "                            C_cell = quality_data[\"C_cell\"].iloc[0]\n",
    "                            C_cell_err = quality_data[\"C_cell_err\"].iloc[0]\n",
    "\n",
    "                            # Calculate fitted curve using cell_scaling\n",
    "                            fitted_curve = cell_scaling(size_range, A_cell, B_cell, C_cell)\n",
    "\n",
    "                            # Calculate uncertainty bands using error propagation\n",
    "                            # For I(n) = C - (n/A)^(-B)\n",
    "                            # Partial derivatives for error propagation\n",
    "                            term = (size_range / A_cell) ** (-B_cell)\n",
    "                            dI_dA = -B_cell * term / A_cell\n",
    "                            dI_dB = term * np.log(size_range / A_cell)\n",
    "                            dI_dC = np.ones_like(size_range)\n",
    "\n",
    "                            # Error propagation: σ_I² = (∂I/∂A)²σ_A² + (∂I/∂B)²σ_B² + (∂I/∂C)²σ_C²\n",
    "                            uncertainty = np.sqrt(\n",
    "                                (dI_dA * A_cell_err) ** 2 + (dI_dB * B_cell_err) ** 2 + (dI_dC * C_cell_err) ** 2\n",
    "                            )\n",
    "\n",
    "                            # Plot uncertainty band (2 sigma)\n",
    "                            ax.fill_between(\n",
    "                                size_range,\n",
    "                                fitted_curve - 2 * uncertainty,\n",
    "                                fitted_curve + 2 * uncertainty,\n",
    "                                color=quality_color_map[quality],\n",
    "                                alpha=0.2,\n",
    "                            )\n",
    "\n",
    "                            # Plot fitted line\n",
    "                            ax.plot(size_range, fitted_curve, color=quality_color_map[quality], linestyle=\"--\", linewidth=2, alpha=0.9)\n",
    "\n",
    "                ax.set_xlabel(\"Cell number\")\n",
    "                ax.set_ylabel(\"MI value\")\n",
    "                ax.set_title(f\"{metric}\\n{method}\")\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.grid(True, alpha=0.3)\n",
    "\n",
    "                # Add legend only to the first subplot\n",
    "                if i == 0 and j == 0:\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "            else:\n",
    "                ax.set_title(f\"{metric}\\n{method}\\n(No data)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fitted data available for plotting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "\n",
    "def info_scaling(x, A, B):\n",
    "    \"\"\"\n",
    "    Information scaling function: I(x) = 0.5 * log2((x*B + 1)/(1 + A*x))\n",
    "    \"\"\"\n",
    "    return 0.5 * np.log2((x * B + 1) / (1 + A * x))\n",
    "\n",
    "\n",
    "def fit_noise_scaling_model(u_values, mi_values):\n",
    "    \"\"\"\n",
    "    Fit the noise scaling model to data and return I_max and u_bar with uncertainties.\n",
    "\n",
    "    Parameters:\n",
    "    u_values: array of UMI per cell values\n",
    "    mi_values: array of mutual information values\n",
    "\n",
    "    Returns:\n",
    "    dict with I_max, u_bar and their uncertainties, plus fit success status\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the noise scaling function for fitting\n",
    "    def info_scaling_local(x, A, B):\n",
    "        \"\"\"\n",
    "        Information scaling function: I(x) = 0.5 * log2((x*B + 1)/(1 + A*x))\n",
    "        \"\"\"\n",
    "        return 0.5 * np.log2((x * B + 1) / (1 + A * x))\n",
    "\n",
    "    def info_max(A, B):\n",
    "        \"\"\"Calculate maximum information\"\"\"\n",
    "        return 0.5 * np.log2(B / A)\n",
    "\n",
    "    # Create lmfit model\n",
    "    model = Model(info_scaling_local)\n",
    "\n",
    "    # Set up parameters with initial values and bounds\n",
    "    params = model.make_params(A=1e-2, B=1e-2)  # initial guesses\n",
    "    params[\"A\"].min = 0  # set bounds\n",
    "    params[\"B\"].min = 0\n",
    "\n",
    "    # Fit the curve\n",
    "    try:\n",
    "        result = model.fit(mi_values, params, x=u_values)\n",
    "        A_info = result.params[\"A\"].value\n",
    "        B_info = result.params[\"B\"].value\n",
    "        A_err = result.params[\"A\"].stderr\n",
    "        B_err = result.params[\"B\"].stderr\n",
    "\n",
    "        # Calculate derived quantities\n",
    "        I_max = info_max(A_info, B_info)\n",
    "        u_bar = 1 / A_info\n",
    "\n",
    "        # Calculate uncertainties using error propagation\n",
    "        # For I_max = 0.5 * log2(B/A), error propagation gives:\n",
    "        I_max_err = 0.5 * np.sqrt((A_err / A_info) ** 2 + (B_err / B_info) ** 2) / np.log(2)\n",
    "\n",
    "        # For u_bar = 1/A, error is |du_bar/dA| * A_err = A_err/A^2\n",
    "        u_bar_err = A_err / (A_info**2)\n",
    "\n",
    "        return {\n",
    "            \"I_max\": I_max,\n",
    "            \"I_max_err\": I_max_err,\n",
    "            \"u_bar\": u_bar,\n",
    "            \"u_bar_err\": u_bar_err,\n",
    "            \"fit_success\": True,\n",
    "            \"result\": result,\n",
    "            \"A_info\": A_info,\n",
    "            \"B_info\": B_info,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Fitting failed: {e}\")\n",
    "        return {\n",
    "            \"I_max\": np.nan,\n",
    "            \"I_max_err\": np.nan,\n",
    "            \"u_bar\": np.nan,\n",
    "            \"u_bar_err\": np.nan,\n",
    "            \"fit_success\": False,\n",
    "            \"result\": None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop to iterate over different datasets, methods, metrics and cell sizes\n",
    "import os\n",
    "\n",
    "# Get unique combinations of dataset, size, method, and metric\n",
    "unique_combinations = df.groupby([\"dataset\", \"size\", \"method\", \"metric\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "print(f\"Found {len(unique_combinations)} unique combinations to fit\")\n",
    "\n",
    "# Initialize list to store all results\n",
    "all_fit_results = []\n",
    "\n",
    "# Loop through each combination\n",
    "for idx, row in unique_combinations.iterrows():\n",
    "    dataset = row[\"dataset\"]\n",
    "    size = row[\"size\"]\n",
    "    method = row[\"method\"]\n",
    "    metric = row[\"metric\"]\n",
    "\n",
    "    print(f\"Processing {idx+1}/{len(unique_combinations)}: {dataset}, {size}, {method}, {metric}\")\n",
    "\n",
    "    # Filter data for current combination\n",
    "    filtered_data = df[\n",
    "        (df[\"dataset\"] == dataset) & (df[\"size\"] == size) & (df[\"method\"] == method) & (df[\"metric\"] == metric)\n",
    "    ]\n",
    "\n",
    "    # Skip if not enough data points\n",
    "    if len(filtered_data) < 3:\n",
    "        print(f\"  Skipping - insufficient data points ({len(filtered_data)})\")\n",
    "        continue\n",
    "\n",
    "    # Extract data for fitting\n",
    "    u_values = filtered_data[\"umis_per_cell\"].values\n",
    "    mi_values = filtered_data[\"mi_value\"].values\n",
    "\n",
    "    # Fit the model\n",
    "    fit_results = fit_noise_scaling_model(u_values, mi_values)\n",
    "\n",
    "    if fit_results[\"fit_success\"]:\n",
    "        print(f\"  Success: I_max={fit_results['I_max']:.4f}, u_bar={fit_results['u_bar']:.1f}\")\n",
    "\n",
    "        # Calculate fitted MI values for the original data points\n",
    "        fitted_mi_values = info_scaling(u_values, fit_results[\"A_info\"], fit_results[\"B_info\"])\n",
    "\n",
    "        # Add new columns to the filtered data\n",
    "        filtered_data_with_fits = filtered_data.copy()\n",
    "        filtered_data_with_fits[\"fitted_mi_value\"] = fitted_mi_values\n",
    "        filtered_data_with_fits[\"I_max\"] = fit_results[\"I_max\"]\n",
    "        filtered_data_with_fits[\"I_max_err\"] = fit_results[\"I_max_err\"]\n",
    "        filtered_data_with_fits[\"u_bar\"] = fit_results[\"u_bar\"]\n",
    "        filtered_data_with_fits[\"u_bar_err\"] = fit_results[\"u_bar_err\"]\n",
    "        filtered_data_with_fits[\"A_fit\"] = fit_results[\"A_info\"]\n",
    "        filtered_data_with_fits[\"B_fit\"] = fit_results[\"B_info\"]\n",
    "\n",
    "        # Append to results list\n",
    "        all_fit_results.append(filtered_data_with_fits)\n",
    "\n",
    "    else:\n",
    "        print(f\"  Failed: Fit unsuccessful\")\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if all_fit_results:\n",
    "    combined_results = pd.concat(all_fit_results, ignore_index=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_filename = \"/home/jupyter/igor_repos/exploration/noise_scaling_laws/Scaling-up-measurement-noise-scaling-laws/fitted_data_with_results.csv\"\n",
    "    combined_results.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nAll fitted data saved to: {output_filename}\")\n",
    "\n",
    "    # Display summary\n",
    "    print(f\"\\nSuccessfully fitted {len(all_fit_results)} combinations\")\n",
    "    print(f\"Total data points with fits: {len(combined_results)}\")\n",
    "\n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst few rows of combined results:\")\n",
    "    display(combined_results.head())\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo successful fits to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7af33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the plot\n",
    "if all_fit_results:\n",
    "    # Get unique combinations of metric and method\n",
    "    metrics = combined_results[\"metric\"].unique()\n",
    "    methods = combined_results[\"method\"].unique()\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(len(metrics), len(methods), figsize=(4 * len(methods), 4 * len(metrics)))\n",
    "\n",
    "    # Handle case where there's only one metric or method\n",
    "    if len(metrics) == 1 and len(methods) == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif len(metrics) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif len(methods) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Color scheme for different sizes\n",
    "    sizes = sorted(combined_results[\"size\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(sizes)))\n",
    "    size_color_map = dict(zip(sizes, colors))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, method in enumerate(methods):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Filter data for this metric and method combination\n",
    "            subset = combined_results[(combined_results[\"metric\"] == metric) & (combined_results[\"method\"] == method)]\n",
    "\n",
    "            if len(subset) > 0:\n",
    "                # Plot points for each size\n",
    "                for size in sizes:\n",
    "                    size_data = subset[subset[\"size\"] == size]\n",
    "                    if len(size_data) > 0:\n",
    "                        # Group by umis_per_cell to handle multiple seeds\n",
    "                        grouped = size_data.groupby(\"umis_per_cell\")\n",
    "\n",
    "                        x_vals = []\n",
    "                        y_means = []\n",
    "                        y_stds = []\n",
    "\n",
    "                        for umis, group in grouped:\n",
    "                            x_vals.append(umis)\n",
    "                            mi_values = group[\"mi_value\"]\n",
    "                            y_means.append(mi_values.mean())\n",
    "                            y_stds.append(mi_values.std() if len(mi_values) > 1 else 0)\n",
    "\n",
    "                        x_vals = np.array(x_vals)\n",
    "                        y_means = np.array(y_means)\n",
    "                        y_stds = np.array(y_stds)\n",
    "\n",
    "                        # Plot error bars if there are multiple seeds, otherwise scatter points\n",
    "                        if np.any(y_stds > 0):\n",
    "                            ax.errorbar(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                yerr=y_stds,\n",
    "                                color=size_color_map[size],\n",
    "                                fmt=\"o\",\n",
    "                                capsize=5,\n",
    "                                capthick=2,\n",
    "                                alpha=0.7,\n",
    "                                markersize=6,\n",
    "                                label=f\"Size {size}\",\n",
    "                            )\n",
    "                        else:\n",
    "                            ax.scatter(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                color=size_color_map[size],\n",
    "                                alpha=0.7,\n",
    "                                s=50,\n",
    "                                label=f\"Size {size}\",\n",
    "                            )\n",
    "\n",
    "                        # Plot fitted line for this size with uncertainty bands\n",
    "                        u_range = np.linspace(size_data[\"umis_per_cell\"].min(), size_data[\"umis_per_cell\"].max(), 100)\n",
    "                        # Use the fitted parameters (they should be the same for all points with same size/metric/method)\n",
    "                        A_fit = size_data[\"A_fit\"].iloc[0]\n",
    "                        B_fit = size_data[\"B_fit\"].iloc[0]\n",
    "                        I_max = size_data[\"I_max\"].iloc[0]\n",
    "                        I_max_err = size_data[\"I_max_err\"].iloc[0]\n",
    "                        u_bar = size_data[\"u_bar\"].iloc[0]\n",
    "                        u_bar_err = size_data[\"u_bar_err\"].iloc[0]\n",
    "\n",
    "                        # Calculate fitted curve\n",
    "                        fitted_curve = info_scaling(u_range, A_fit, B_fit)\n",
    "\n",
    "                        # Calculate uncertainty bands using error propagation\n",
    "                        # For I(u) = I_max * (1 - exp(-u/u_bar))\n",
    "                        # We need to propagate errors from I_max and u_bar\n",
    "\n",
    "                        # Partial derivatives for error propagation\n",
    "                        exp_term = np.exp(-u_range / u_bar)\n",
    "                        dI_dImax = 1 - exp_term\n",
    "                        dI_dubar = I_max * exp_term * u_range / (u_bar**2)\n",
    "\n",
    "                        # Error propagation: σ_I² = (∂I/∂I_max)²σ_I_max² + (∂I/∂u_bar)²σ_u_bar²\n",
    "                        uncertainty = np.sqrt((dI_dImax * I_max_err) ** 2 + (dI_dubar * u_bar_err) ** 2)\n",
    "\n",
    "                        # Plot uncertainty band (2 sigma)\n",
    "                        ax.fill_between(\n",
    "                            u_range,\n",
    "                            fitted_curve - 2 * uncertainty,\n",
    "                            fitted_curve + 2 * uncertainty,\n",
    "                            color=size_color_map[size],\n",
    "                            alpha=0.2,\n",
    "                        )\n",
    "\n",
    "                        # Plot fitted line\n",
    "                        ax.plot(u_range, fitted_curve, color=size_color_map[size], linestyle=\"-\", linewidth=2)\n",
    "\n",
    "                ax.set_xlabel(\"UMIs per cell\")\n",
    "                ax.set_ylabel(\"MI value\")\n",
    "                ax.set_title(f\"{metric}\\n{method}\")\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.grid(True, alpha=0.3)\n",
    "\n",
    "                # Add legend only to the first subplot\n",
    "                if i == 0 and j == 0:\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "            else:\n",
    "                ax.set_title(f\"{metric}\\n{method}\\n(No data)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fitted data available for plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fff5b8",
   "metadata": {},
   "source": [
    "### fitting cell scaling laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop to iterate over different datasets, methods, metrics and cell sizes\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "\n",
    "def cell_number_scaling(x, A, B, C):\n",
    "    \"\"\"\n",
    "    Cell number scaling function: f(x) = C - (x/A)^(-B)\n",
    "    \"\"\"\n",
    "    return C - (x / A) ** (-B)\n",
    "\n",
    "\n",
    "def fit_cell_scaling_model(x_values, mi_values, mi_key=None):\n",
    "    \"\"\"\n",
    "    Fit the cell number scaling model to data and return parameters with uncertainties.\n",
    "\n",
    "    Parameters:\n",
    "    x_values: array of cell number values\n",
    "    mi_values: array of mutual information values\n",
    "    mi_key: string indicating which MI metric is being fitted (for parameter initialization)\n",
    "\n",
    "    Returns:\n",
    "    dict with A, B, C parameters and their uncertainties, plus fit success status\n",
    "    \"\"\"\n",
    "\n",
    "    # Create lmfit model\n",
    "    model = Model(cell_number_scaling)\n",
    "\n",
    "    # Set up parameters with initial values and bounds\n",
    "    if mi_key == \"Spatial neighborhood MI\":\n",
    "        params = model.make_params(\n",
    "            A=dict(value=10**3, min=1e-6),\n",
    "            B=dict(value=1, min=1e-3),\n",
    "            C=dict(value=1, min=mi_values.max(), max=mi_values.max() * 2),\n",
    "        )\n",
    "    else:\n",
    "        params = model.make_params(\n",
    "            A=dict(value=10**4, min=1e-6),\n",
    "            B=dict(value=1, min=1e-6),\n",
    "            C=dict(value=1, min=mi_values.max(), max=mi_values.max() * 1.5),\n",
    "        )\n",
    "\n",
    "    # Fit the curve\n",
    "    try:\n",
    "        result = model.fit(mi_values, params, x=x_values)\n",
    "        A_fit = result.params[\"A\"].value\n",
    "        B_fit = result.params[\"B\"].value\n",
    "        C_fit = result.params[\"C\"].value\n",
    "        A_err = result.params[\"A\"].stderr\n",
    "        B_err = result.params[\"B\"].stderr\n",
    "        C_err = result.params[\"C\"].stderr\n",
    "\n",
    "        return {\n",
    "            \"A\": A_fit,\n",
    "            \"A_err\": A_err,\n",
    "            \"B\": B_fit,\n",
    "            \"B_err\": B_err,\n",
    "            \"C\": C_fit,\n",
    "            \"C_err\": C_err,\n",
    "            \"fit_success\": True,\n",
    "            \"result\": result,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"A\": np.nan,\n",
    "            \"A_err\": np.nan,\n",
    "            \"B\": np.nan,\n",
    "            \"B_err\": np.nan,\n",
    "            \"C\": np.nan,\n",
    "            \"C_err\": np.nan,\n",
    "            \"fit_success\": False,\n",
    "            \"result\": None,\n",
    "        }\n",
    "\n",
    "\n",
    "# Get unique combinations of dataset, method, and metric (cell size scaling)\n",
    "unique_combinations = df.groupby([\"dataset\", \"method\", \"metric\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Initialize list to store all results\n",
    "all_cell_fit_results = []\n",
    "# Initialize list to store fit parameters summary\n",
    "cell_fit_parameters_summary = []\n",
    "\n",
    "# Loop through each combination\n",
    "for idx, row in unique_combinations.iterrows():\n",
    "    dataset = row[\"dataset\"]\n",
    "    method = row[\"method\"]\n",
    "    metric = row[\"metric\"]\n",
    "\n",
    "    # Filter data for current combination\n",
    "    filtered_data = df[(df[\"dataset\"] == dataset) & (df[\"method\"] == method) & (df[\"metric\"] == metric)]\n",
    "\n",
    "    # Group by size and average MI values across seeds for each size\n",
    "    size_averaged_data = filtered_data.groupby(\"size\")[\"mi_value\"].mean().reset_index()\n",
    "\n",
    "    # Skip if not enough data points\n",
    "    if len(size_averaged_data) < 3:\n",
    "        continue\n",
    "\n",
    "    # Extract data for fitting\n",
    "    size_values = size_averaged_data[\"size\"].values\n",
    "    mi_values = size_averaged_data[\"mi_value\"].values\n",
    "\n",
    "    # Fit the model\n",
    "    fit_results = fit_cell_scaling_model(size_values, mi_values)\n",
    "\n",
    "    if fit_results[\"fit_success\"]:\n",
    "        # Calculate fitted MI values for all original data points\n",
    "        fitted_mi_values = cell_number_scaling(\n",
    "            filtered_data[\"size\"].values, fit_results[\"A\"], fit_results[\"B\"], fit_results[\"C\"]\n",
    "        )\n",
    "\n",
    "        # Add new columns to the filtered data\n",
    "        filtered_data_with_fits = filtered_data.copy()\n",
    "        filtered_data_with_fits[\"fitted_mi_value_cell\"] = fitted_mi_values\n",
    "        filtered_data_with_fits[\"A_cell\"] = fit_results[\"A\"]\n",
    "        filtered_data_with_fits[\"A_cell_err\"] = fit_results[\"A_err\"]\n",
    "        filtered_data_with_fits[\"B_cell\"] = fit_results[\"B\"]\n",
    "        filtered_data_with_fits[\"B_cell_err\"] = fit_results[\"B_err\"]\n",
    "        filtered_data_with_fits[\"C_cell\"] = fit_results[\"C\"]\n",
    "        filtered_data_with_fits[\"C_cell_err\"] = fit_results[\"C_err\"]\n",
    "\n",
    "        # Append to results list\n",
    "        all_cell_fit_results.append(filtered_data_with_fits)\n",
    "\n",
    "        # Store fit parameters summary\n",
    "        cell_fit_parameters_summary.append(\n",
    "            {\n",
    "                \"dataset\": dataset,\n",
    "                \"method\": method,\n",
    "                \"metric\": metric,\n",
    "                \"A_cell\": fit_results[\"A\"],\n",
    "                \"A_cell_err\": fit_results[\"A_err\"],\n",
    "                \"B_cell\": fit_results[\"B\"],\n",
    "                \"B_cell_err\": fit_results[\"B_err\"],\n",
    "                \"C_cell\": fit_results[\"C\"],\n",
    "                \"C_cell_err\": fit_results[\"C_err\"],\n",
    "                \"n_size_points\": len(size_averaged_data),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Combine cell scaling results with original data\n",
    "if all_cell_fit_results:\n",
    "    combined_cell_results = pd.concat(all_cell_fit_results, ignore_index=True)\n",
    "\n",
    "    # Merge with existing fitted data if it exists\n",
    "    if \"combined_results\" in locals():\n",
    "        # Merge on all common columns\n",
    "        merge_cols = [\"dataset\", \"size\", \"quality\", \"method\", \"metric\", \"seed\", \"mi_value\", \"umis_per_cell\"]\n",
    "        final_results = pd.merge(\n",
    "            combined_results,\n",
    "            combined_cell_results[\n",
    "                merge_cols\n",
    "                + [\"fitted_mi_value_cell\", \"A_cell\", \"A_cell_err\", \"B_cell\", \"B_cell_err\", \"C_cell\", \"C_cell_err\"]\n",
    "            ],\n",
    "            on=merge_cols,\n",
    "            how=\"outer\",\n",
    "        )\n",
    "    else:\n",
    "        # If no UMI scaling fits exist, use cell scaling results as base\n",
    "        final_results = combined_cell_results\n",
    "else:\n",
    "    # If no cell scaling fits, keep the UMI scaling results as final results\n",
    "    if \"combined_results\" in locals():\n",
    "        final_results = combined_results\n",
    "\n",
    "# Save final results to CSV\n",
    "final_results.to_csv(\n",
    "    \"/home/jupyter/igor_repos/exploration/noise_scaling_laws/Scaling-up-measurement-noise-scaling-laws/fitted_data_with_results.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "if all_fit_results:\n",
    "    # Get unique combinations of metric and method\n",
    "    metrics = combined_results[\"metric\"].unique()\n",
    "    methods = combined_results[\"method\"].unique()\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(len(metrics), len(methods), figsize=(4 * len(methods), 4 * len(metrics)))\n",
    "\n",
    "    # Handle case where there's only one metric or method\n",
    "    if len(metrics) == 1 and len(methods) == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif len(metrics) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif len(methods) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Color scheme for different sizes\n",
    "    sizes = sorted(combined_results[\"size\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(sizes)))\n",
    "    size_color_map = dict(zip(sizes, colors))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, method in enumerate(methods):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            # Filter data for this metric and method combination\n",
    "            subset = combined_results[(combined_results[\"metric\"] == metric) & (combined_results[\"method\"] == method)]\n",
    "\n",
    "            if len(subset) > 0:\n",
    "                # Plot points for each size\n",
    "                for size in sizes:\n",
    "                    size_data = subset[subset[\"size\"] == size]\n",
    "                    if len(size_data) > 0:\n",
    "                        # Group by umis_per_cell to handle multiple seeds\n",
    "                        grouped = size_data.groupby(\"umis_per_cell\")\n",
    "\n",
    "                        x_vals = []\n",
    "                        y_means = []\n",
    "                        y_stds = []\n",
    "\n",
    "                        for umis, group in grouped:\n",
    "                            x_vals.append(umis)\n",
    "                            mi_values = group[\"mi_value\"]\n",
    "                            y_means.append(mi_values.mean())\n",
    "                            y_stds.append(mi_values.std() if len(mi_values) > 1 else 0)\n",
    "\n",
    "                        x_vals = np.array(x_vals)\n",
    "                        y_means = np.array(y_means)\n",
    "                        y_stds = np.array(y_stds)\n",
    "\n",
    "                        # Plot error bars if there are multiple seeds, otherwise scatter points\n",
    "                        if np.any(y_stds > 0):\n",
    "                            ax.errorbar(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                yerr=y_stds,\n",
    "                                color=size_color_map[size],\n",
    "                                fmt=\"o\",\n",
    "                                capsize=5,\n",
    "                                capthick=2,\n",
    "                                alpha=0.7,\n",
    "                                markersize=6,\n",
    "                                label=f\"Size {size}\",\n",
    "                            )\n",
    "                        else:\n",
    "                            ax.scatter(\n",
    "                                x_vals,\n",
    "                                y_means,\n",
    "                                color=size_color_map[size],\n",
    "                                alpha=0.7,\n",
    "                                s=50,\n",
    "                                label=f\"Size {size}\",\n",
    "                            )\n",
    "\n",
    "                        # Plot fitted line for this size with uncertainty bands\n",
    "                        u_range = np.linspace(size_data[\"umis_per_cell\"].min(), size_data[\"umis_per_cell\"].max(), 100)\n",
    "                        # Use the fitted parameters (they should be the same for all points with same size/metric/method)\n",
    "                        A_fit = size_data[\"A_fit\"].iloc[0]\n",
    "                        B_fit = size_data[\"B_fit\"].iloc[0]\n",
    "                        I_max = size_data[\"I_max\"].iloc[0]\n",
    "                        I_max_err = size_data[\"I_max_err\"].iloc[0]\n",
    "                        u_bar = size_data[\"u_bar\"].iloc[0]\n",
    "                        u_bar_err = size_data[\"u_bar_err\"].iloc[0]\n",
    "\n",
    "                        # Calculate fitted curve\n",
    "                        fitted_curve = info_scaling(u_range, A_fit, B_fit)\n",
    "\n",
    "                        # Calculate uncertainty bands using error propagation\n",
    "                        # For I(u) = I_max * (1 - exp(-u/u_bar))\n",
    "                        # We need to propagate errors from I_max and u_bar\n",
    "\n",
    "                        # Partial derivatives for error propagation\n",
    "                        exp_term = np.exp(-u_range / u_bar)\n",
    "                        dI_dImax = 1 - exp_term\n",
    "                        dI_dubar = I_max * exp_term * u_range / (u_bar**2)\n",
    "\n",
    "                        # Error propagation: σ_I² = (∂I/∂I_max)²σ_I_max² + (∂I/∂u_bar)²σ_u_bar²\n",
    "                        uncertainty = np.sqrt((dI_dImax * I_max_err) ** 2 + (dI_dubar * u_bar_err) ** 2)\n",
    "\n",
    "                        # Plot uncertainty band (2 sigma)\n",
    "                        ax.fill_between(\n",
    "                            u_range,\n",
    "                            fitted_curve - 2 * uncertainty,\n",
    "                            fitted_curve + 2 * uncertainty,\n",
    "                            color=size_color_map[size],\n",
    "                            alpha=0.2,\n",
    "                        )\n",
    "\n",
    "                        # Plot fitted line\n",
    "                        ax.plot(u_range, fitted_curve, color=size_color_map[size], linestyle=\"-\", linewidth=2)\n",
    "\n",
    "                ax.set_xlabel(\"UMIs per cell\")\n",
    "                ax.set_ylabel(\"MI value\")\n",
    "                ax.set_title(f\"{metric}\\n{method}\")\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.grid(True, alpha=0.3)\n",
    "\n",
    "                # Add legend only to the first subplot\n",
    "                if i == 0 and j == 0:\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "            else:\n",
    "                ax.set_title(f\"{metric}\\n{method}\\n(No data)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fitted data available for plotting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
